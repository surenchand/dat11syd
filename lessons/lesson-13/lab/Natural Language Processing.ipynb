{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science with Python \n",
    "## General Assembly\n",
    "## Natural Language Processing (NLP)\n",
    "\n",
    "Make sure you have installed spacy ( `!pip install spacy` ) and successfully run `!python -m spacy download en` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 1\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "What:  Separate text into units such as sentences or words\n",
    "\n",
    "Why:   Gives structure to previously unstructured text\n",
    "\n",
    "Notes: Relatively easy with English language text, not easy with some languages\n",
    "\n",
    "\n",
    "\"corpus\" = collection of documents\n",
    "\n",
    "\"corpora\" = plural form of corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jane Austen's Emma is in the `data/` directory as `emma.txt`\n",
    "If you are using a Azure Notebook, upload it somewhere \n",
    "convenient (e.g. `~/library`) and adjust the path in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open it as a UTF-8 file.\n",
    "emma_file = codecs.open('../../data/emma.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an NLP analysis of the first 5000 characters of Emma:\n",
    "emma = nlp(emma_file.read()[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same for Alice in Wonderland, which is in the data/ directory\n",
    "# as alice-in-wonderland.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of sentences in each novel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of words in each sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which novel has more average words per sentence?\n",
    "# Given their target audience, is this what you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each novel, construct a set of all the distinct words used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the lexical diversity of each novel (distinct words / word count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Optional, only for the very keen)\n",
    "# The nltk library includes a sample of project Gutenberg books in nltk.corpus.gutenberg\n",
    "# Create a dataframe with the names of the novels, when they were written,\n",
    "# whether they were for children, the lexical diversity and the average sentence length.\n",
    "# Can you use logistic regression to predict the audience, based on the content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 2\n",
    "\n",
    "Words in context. The textacy library has some utility functions that make this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textacy\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does Jane Austen ever mention the word 'young' in Emma? What about Lewis Carroll?\n",
    "# In what context does it appear?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where does the word 'cat' appear in Alice in Wonderland?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 3 Part of speech tagging\n",
    "\n",
    "What:  Determine the part of speech of a word\n",
    "    \n",
    "Why:   This can inform other methods and models such as Named Entity Recognition\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jane Austen is very long-winded. The 25th sentence of Emma isn't\n",
    "# too bad though: \"She dearly loved her father, but he was no companion for her.\"\n",
    "#\n",
    "emma25 = list(emma.sents)[25]\n",
    "print(emma25.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out each word in this sentence and its part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Optional extra)\n",
    "# Who are the most commonly named characters in Emma? What about Alice in Wonderland?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Optional extra; harder)\n",
    "# What are the most commonly referenced nouns that are not characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 4 - Vectorisation\n",
    "\n",
    "What: Turn sentences and documents into arrays of numbers\n",
    "\n",
    "Why:  Then we can use machine learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a count vectorizer (or tfidf vectorizer) to vectorise all the sentences\n",
    "# in both Emma and Alice in Wonderland (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many sentences are there in Emma? Create a list of this length filled with the number zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many sentences are there in Alice in Wonderland? Create a list of this length filled with the number one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list called 'which_document' by appending the second list to the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a KNearestCentroid classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train your KNearestCentroid classifier. Let X be the vectorisation of sentences, and let y\n",
    "# be the 'which_document' list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make up a sentence about love, marriage and any other Jane Austen topics. \n",
    "# Transform it using your vectorizer, and then get your classifier to predict what sort of document\n",
    "# it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FWIW, a TFIDF vectoriser combined with KNearestCentroid classifier is known as a Rocchio search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat lab 4 using spacy's implementation of word2vec as the vectoriser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
