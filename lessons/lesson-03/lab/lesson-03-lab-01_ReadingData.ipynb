{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## General Assembly DAT11 Sydney - 26th Feb 2018 ##\n",
    "\n",
    "## Reading data from some simple sources\n",
    "\n",
    "This notebook contains exercises for getting started with visualising data analysis in Python. The 3 main topics we will cover in this class are:\n",
    "1. Reading in data from different sources\n",
    "2. Manipulating data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data from different sources\n",
    "1. Reading in from a URL\n",
    "2. Reading in from an excel spreadsheet\n",
    "3. Reading in from a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset from CSV URL\n",
    "# 1. Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Specify the URL for the Iris dataset (UCI Machine Learning Repository)\n",
    "url = \"http://goo.gl/HppjFh\"\n",
    "\n",
    "# 3. Download the file\n",
    "raw_data = urllib.request.urlopen(url)\n",
    "\n",
    "# 4. Load the CSV file as a numpy matrix\n",
    "#dataset = pd.read_csv(raw_data, delimiter=\",\")\n",
    "dataset = pd.read_csv(raw_data, delimiter=\",\", names=('sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'))\n",
    "#print(dataset.shape)\n",
    "dataset.head()\n",
    "\n",
    "# Refer to http://pandas.pydata.org/pandas-docs/version/0.15.0/io.html#io-read-csv-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from an excel spreadsheet\n",
    "# 1. Load the file into python\n",
    "xl = pd.ExcelFile(\"../../../data/iris.xlsx\")\n",
    "# 2. Find what sheets are in the workbook\n",
    "xl.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Read in the dataset from the 'Iris' sheet\n",
    "df = xl.parse(\"iris\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: To write the file to excel format we can use the 'to_excel' method\n",
    "df.to_excel('iris_saved_v2.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from a csv\n",
    "iris_data = pd.read_csv('iris.csv')\n",
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To write the file to csv format we can use the 'to_csv' method\n",
    "df.to_csv('iris_saved2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Data in Python\n",
    "In this section we will begin summarise the data and get an idea of the distribution of our data and what type of cleaning it requires. This is an essential step of a data science project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a count of the number of rows in the DataFrame\n",
    "len(iris_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the DataFrame\n",
    "iris_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise the data\n",
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the observations with petal_length < 1.7\n",
    "iris_data[(iris_data['petal_length']<1.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's group the data by the species\n",
    "byspecies = iris_data.groupby('species')\n",
    "byspecies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a function by a group (Species)\n",
    "# You can try mean, max, median, etc\n",
    "byspecies['petal_length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also aggregate by group (makes little sense in this context but this will come in handy)\n",
    "byspecies['petal_length'].aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also aggregate by group (makes little sense in this context but this will come in handy)\n",
    "byspecies['petal_length'].agg([len, np.mean, np.std])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
